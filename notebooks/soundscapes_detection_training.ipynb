{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "soundscapes_detection_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "WOLSv6m41MSn"
      },
      "source": [
        "# Soundscape detection\n",
        "\n",
        "Author: Edoardo De Matteis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NBIjvnakAQq"
      },
      "source": [
        "This notebook has been used to train the model used for the binary classification task of soundscape detection i.e. a system that detects (bird) sounds in an ambient recording. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYhbtvU-1f5A"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "i-MUoBQW1MSp"
      },
      "source": [
        "!pip install torchaudio\n",
        "!pip install torchinfo\n",
        "!pip install pytorch_lightning\n",
        "!pip install wandb -qqq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IyqqzvVe1MSr"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, Optional, Tuple, Union, Callable, List, Any\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchmetrics\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Callback, seed_everything\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from torchinfo import summary\n",
        "\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQn37GuA1qvM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbYWXgM61teN"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/Colab\\ Notebooks/Birdcalls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djPypEdi1S64"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3R1z-ftmAAQ"
      },
      "source": [
        "Let's define some basic functions that will help us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "10bRDPf_1MSu"
      },
      "source": [
        "def cnn_size(\n",
        "    input: Tuple[int, int],\n",
        "    kernel: Union[int, Tuple[int, int]],\n",
        "    padding: Union[int, Tuple[int, int]] = 0,\n",
        "    stride: Union[int, Tuple[int, int]] = 1,\n",
        ") -> Tuple[int, int]:\n",
        "    \"\"\"\n",
        "    Return the size of the output of a convolutional layer.\n",
        "    :param input: Size of the input image.\n",
        "    :param kernel: Kernel size, it is assumed to be a square.\n",
        "    :param padding: Padding size.\n",
        "    :param stride: Stride.\n",
        "    :return: The output size.\n",
        "    \"\"\"\n",
        "    if isinstance(kernel, int):\n",
        "        kernel = (kernel, kernel)\n",
        "\n",
        "    if isinstance(padding, int):\n",
        "        padding = (padding, padding)\n",
        "\n",
        "    if isinstance(stride, int):\n",
        "        stride = (stride, stride)\n",
        "\n",
        "    out_w = (input[0] - kernel[0] + 2 * padding[0]) / stride[0] + 1\n",
        "    out_h = (input[1] - kernel[1] + 2 * padding[1]) / stride[1] + 1\n",
        "    return int(out_w), int(out_h)\n",
        "\n",
        "def pool_size(\n",
        "    input: Union[int, Tuple[int, int]],\n",
        "    pooling: Union[int, Tuple[int, int]],\n",
        ") -> Tuple[int, int]:\n",
        "    \"\"\"\n",
        "    Return the size of the output of a convolutional layer.\n",
        "    :param input: Size of the input image.\n",
        "    :param pooling: Pooling size.\n",
        "    :return: The output size.\n",
        "    \"\"\"\n",
        "    if isinstance(pooling, int):\n",
        "        pooling = (pooling, pooling)\n",
        "\n",
        "    out_w = input[0] / pooling[0]\n",
        "    out_h = input[1] / pooling[1]\n",
        "    return int(out_w), int(out_h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "u1pNwVbE1MSv"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK6ZKVX3meWa"
      },
      "source": [
        "We define the dataset object, for our purposes we only care about the offline dataset.\n",
        "Therefore we only define loading methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "N4giaaM91MSw"
      },
      "source": [
        "class SoundscapeDataset(Dataset):\n",
        "    def __init__(\n",
        "        self, csv_path: Optional[str], online: bool, debug: int, load: bool, **kwargs\n",
        "    ):\n",
        "        \"\"\"\n",
        "        :param csv_path: Path of the training CSV file.\n",
        "        :param online: If true tensors are computed on-the-fly by the dataloader, otherwise they are all precomputed.\n",
        "        :param debug: Defines the size of the reduced dataset (it is shuffled beforehand) we want to use, any number\n",
        "        below or equal to 0 means that we keep the whole dataset.\n",
        "        :param load: If true we do not compute anything and will load values from a file.\n",
        "        :param kwargs:\n",
        "        \"\"\"\n",
        "        super(SoundscapeDataset, self).__init__()\n",
        "\n",
        "        self.online = online\n",
        "        self.len: int\n",
        "\n",
        "        self.spectrograms: torch.Tensor\n",
        "        self.targets: torch.Tensor\n",
        "\n",
        "    @staticmethod\n",
        "    def load(\n",
        "        spectrograms_path: Union[str, Path], targets_path: Union[str, Path], **kwargs\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Load a dataset whose spectorgrams and targets are loaded from .pt files.\n",
        "        :param spectrograms_path: Path of the spectrograms tensor file.\n",
        "        :param targets_path: Path of the targets tensor file.\n",
        "        :param kwargs:\n",
        "        :return: A SoundscapeDataset object with populated tensors.\n",
        "        \"\"\"\n",
        "        ds = SoundscapeDataset(csv_path=None, online=False, debug=-1, load=True)\n",
        "\n",
        "        ds.spectrograms = torch.load(spectrograms_path)\n",
        "        ds.targets = torch.load(targets_path)\n",
        "        ds.len = len(ds.targets)\n",
        "\n",
        "        return ds\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        :return: Length of the dataset.\n",
        "        \"\"\"\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"\n",
        "        :param item: Index of the item to retrieve.\n",
        "        :return: The item-th entry.\n",
        "        \"\"\"\n",
        "        if self.online:\n",
        "            return {\n",
        "                \"row_id\": self.row_id[item],\n",
        "                \"site\": self.site[item],\n",
        "                \"audio_id\": self.audio_id[item],\n",
        "                \"seconds\": self.seconds[item],\n",
        "                \"birds\": self.birds[item],\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                \"spectrograms\": self.spectrograms[item],\n",
        "                \"targets\": self.targets[item],\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qwsu9vC71MSw"
      },
      "source": [
        "class SoundscapesDataModule(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_workers: Dict,\n",
        "        batch_size: Dict,\n",
        "        shuffle: Dict,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.num_workers = num_workers\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        # These attributes will be populated after self.setup() call.\n",
        "        self.train_ds: Optional[Dataset] = None\n",
        "        self.val_ds: Optional[Dataset] = None\n",
        "        self.test_ds: Optional[Dataset] = None\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None) -> None:\n",
        "        if stage is None or stage == \"fit\":\n",
        "            # Train\n",
        "            self.train_ds = SoundscapeDataset.load(\n",
        "                spectrograms_path=TRAIN_SPECTROGRAMS,\n",
        "                targets_path=TRAIN_TARGETS\n",
        "            )\n",
        "\n",
        "            # Val\n",
        "            self.val_ds = SoundscapeDataset.load(\n",
        "                spectrograms_path=VAL_SPECTROGRAMS,\n",
        "                targets_path=VAL_TARGETS\n",
        "            )\n",
        "\n",
        "        if stage is None or stage == \"test\":\n",
        "            # Test\n",
        "            self.test_ds = SoundscapeDataset.load(\n",
        "                spectrograms_path=TEST_SPECTROGRAMS,\n",
        "                targets_path=TEST_TARGETS\n",
        "            )\n",
        "\n",
        "    def train_dataloader(\n",
        "        self,\n",
        "    ) -> Union[DataLoader, List[DataLoader], Dict[str, DataLoader]]:\n",
        "        batch_size = self.batch_size[\"train\"]\n",
        "        shuffle = self.shuffle[\"train\"]\n",
        "\n",
        "        dl = DataLoader(\n",
        "            dataset=self.train_ds,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "        )\n",
        "\n",
        "        return dl\n",
        "\n",
        "    def val_dataloader(self) -> Union[DataLoader, List[DataLoader]]:\n",
        "        batch_size = self.batch_size[\"val\"]\n",
        "        shuffle = self.shuffle[\"val\"]\n",
        "\n",
        "        dl = DataLoader(\n",
        "            dataset=self.val_ds,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "        )\n",
        "\n",
        "        return dl\n",
        "    \n",
        "    def test_dataloader(self) -> Union[DataLoader, List[DataLoader]]:\n",
        "        batch_size = self.batch_size[\"test\"]\n",
        "        shuffle = self.shuffle[\"test\"]\n",
        "\n",
        "        dl = DataLoader(\n",
        "            dataset=self.test_ds,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "        )\n",
        "\n",
        "        return dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "ZWhT_v-r1MSx"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x35P3XPVnFrw"
      },
      "source": [
        "For all the model definition refer to the project directories `Birdcalls.src.pl_module` and `Birdcalls.our.models`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cJShRISM1MSx"
      },
      "source": [
        "class Detection(nn.Module):\n",
        "    # Shape of the input image (c,h,w)\n",
        "    shape = torch.Size((1, 128, 313))\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=3,\n",
        "            kernel_size=1\n",
        "        )\n",
        "        self.resnet = torchvision.models.resnet50(pretrained=True)\n",
        "        self.fc = nn.Linear(in_features=1000, out_features=1)\n",
        "    \n",
        "    def forward(self, xb):\n",
        "        out = self.cnn(xb)\n",
        "        out = self.resnet(out)\n",
        "        logits = self.fc(out)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6LWl2k9L1MSx"
      },
      "source": [
        "class SoundscapeDetection(pl.LightningModule):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(SoundscapeDetection, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.model = Detection()\n",
        "\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        accuracy = torchmetrics.Accuracy()\n",
        "        self.train_accuracy = accuracy.clone()\n",
        "        self.val_accuracy = accuracy.clone()\n",
        "        self.test_accuracy = accuracy.clone()\n",
        "\n",
        "        precision = torchmetrics.Precision()\n",
        "        self.train_precision = precision.clone()\n",
        "        self.val_precision = precision.clone()\n",
        "        self.test_precision = precision.clone()\n",
        "\n",
        "        recall = torchmetrics.Recall()\n",
        "        self.train_recall = recall.clone()\n",
        "        self.val_recall = recall.clone()\n",
        "        self.test_recall = recall.clone()\n",
        "\n",
        "        self.conf_mat = torchmetrics.ConfusionMatrix(num_classes=2)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        logits = self.model(xb)\n",
        "        # The loss function does implement the sigmoid by itself.\n",
        "        preds = torch.sigmoid(logits).squeeze(1).ge(0.5).to(torch.long)\n",
        "        return logits, preds\n",
        "\n",
        "    def step(self, x: torch.Tensor, y: torch.Tensor):\n",
        "        logits, preds = self(x)\n",
        "        loss = self.loss(logits, y)\n",
        "        return {\"logits\": logits, \"preds\": preds, \"loss\": loss}\n",
        "\n",
        "    def training_step(self, batch: Any, batch_idx: int) -> torch.Tensor:\n",
        "        targets = batch[\"targets\"]\n",
        "        specs = batch[\"spectrograms\"]\n",
        "\n",
        "        out_step = self.step(x=specs, y=targets)\n",
        "\n",
        "        x = out_step[\"preds\"]\n",
        "        y = targets.squeeze(1).to(torch.long)\n",
        "\n",
        "        self.train_accuracy(x, y)\n",
        "        self.train_precision(x, y)\n",
        "        self.train_recall(x, y)\n",
        "\n",
        "        self.log_dict(\n",
        "            {\n",
        "                \"train_loss\": out_step[\"loss\"],\n",
        "                \"train_acc\": self.train_accuracy.compute(),\n",
        "                \"train_prec\": self.train_precision.compute(),\n",
        "                \"train_rec\": self.train_recall.compute(),\n",
        "            }\n",
        "        )\n",
        "        return out_step[\"loss\"]\n",
        "\n",
        "    def validation_step(self, batch: Any, batch_idx: int):\n",
        "        targets = batch[\"targets\"]\n",
        "        specs = batch[\"spectrograms\"]\n",
        "        out_step = self.step(x=specs, y=targets)\n",
        "\n",
        "        x = out_step[\"preds\"]\n",
        "        y = targets.squeeze(1).to(torch.long)\n",
        "\n",
        "        self.val_accuracy(x, y)\n",
        "        self.val_precision(x, y)\n",
        "        self.val_recall(x, y)\n",
        "\n",
        "        self.log_dict(\n",
        "            {\n",
        "                \"val_loss\": out_step[\"loss\"],\n",
        "                \"val_acc\": self.val_accuracy.compute(),\n",
        "                \"val_prec\": self.val_precision.compute(),\n",
        "                \"val_rec\": self.val_recall.compute(),\n",
        "            }\n",
        "        )\n",
        "        return out_step[\"loss\"]\n",
        "\n",
        "    def test_step(self, batch: Any, batch_idx: int):\n",
        "        targets = batch[\"targets\"]\n",
        "        specs = batch[\"spectrograms\"]\n",
        "        out_step = self.step(x=specs, y=targets)\n",
        "\n",
        "        x = out_step[\"preds\"]\n",
        "        y = targets.squeeze(1).to(torch.long)\n",
        "\n",
        "        self.test_accuracy(x, y)\n",
        "        self.test_precision(x, y)\n",
        "        self.test_recall(x, y)\n",
        "\n",
        "        self.log_dict(\n",
        "            {\n",
        "                \"test_acc\": self.test_accuracy.compute(),\n",
        "                \"test_prec\": self.test_precision.compute(),\n",
        "                \"test_rec\": self.test_recall.compute(),\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.logger.experiment.log(\n",
        "            {\n",
        "                \"conf_mat\": wandb.plot.confusion_matrix(\n",
        "                    probs=None,\n",
        "                    preds=x.cpu(),\n",
        "                    y_true=y.cpu(),\n",
        "                    class_names=[\"nocall\", \"call\"],\n",
        "                )\n",
        "            }\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt = self.hparams.optim[\"optimizer\"][\"fn\"](\n",
        "            params=self.parameters(),\n",
        "            lr=self.hparams.optim[\"optimizer\"][\"lr\"],\n",
        "            betas=self.hparams.optim[\"optimizer\"][\"betas\"],\n",
        "            eps=self.hparams.optim[\"optimizer\"][\"eps\"],\n",
        "            weight_decay=self.hparams.optim[\"optimizer\"][\"weight_decay\"],\n",
        "        )\n",
        "\n",
        "\n",
        "        if not self.hparams.optim[\"use_lr_scheduler\"]:\n",
        "            return {\"optimizer\": opt}\n",
        "        else:\n",
        "            scheduler = self.hparams.optim[\"lr_scheduler\"][\"fn\"](\n",
        "                optimizer=opt,\n",
        "                T_0=self.hparams.optim[\"lr_scheduler\"][\"T_0\"],\n",
        "                T_mult=self.hparams.optim[\"lr_scheduler\"][\"T_mult\"],\n",
        "                eta_min=self.hparams.optim[\"lr_scheduler\"][\"eta_min\"],\n",
        "                last_epoch=self.hparams.optim[\"lr_scheduler\"][\"last_epoch\"],\n",
        "                verbose=self.hparams.optim[\"lr_scheduler\"][\"verbose\"],\n",
        "            )\n",
        "            return {\"optimizer\": opt, \"lr_scheduler\": scheduler}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "FWKYXIaq1MSx"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r-91vOBj89J"
      },
      "source": [
        "Environmental and setup variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "imRet6j31MSs"
      },
      "source": [
        "TRAIN_SPECTROGRAMS= Path(\"/content/gdrive/My Drive/Colab Notebooks/Birdcalls/out/precomputed/train/soundscapes/spectrograms.pt\")\n",
        "TRAIN_TARGETS= Path(\"/content/gdrive/My Drive/Colab Notebooks/Birdcalls/out/precomputed/train/soundscapes/targets.pt\")\n",
        "\n",
        "VAL_SPECTROGRAMS= Path(\"/content/gdrive/My Drive/Colab Notebooks/Birdcalls/out/precomputed/val/soundscapes/spectrograms.pt\")\n",
        "VAL_TARGETS= Path(\"/content/gdrive/My Drive/Colab Notebooks/Birdcalls/out/precomputed/val/soundscapes/targets.pt\")\n",
        "\n",
        "TEST_SPECTROGRAMS= Path(\"/content/gdrive/My Drive/Colab Notebooks/Birdcalls/out/precomputed/test/soundscapes/spectrograms.pt\")\n",
        "TEST_TARGETS= Path(\"/content/gdrive/My Drive/Colab Notebooks/Birdcalls/out/precomputed/test/soundscapes/targets.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "j3A7DBgQ1MSx"
      },
      "source": [
        "num_workers = {'train': 12, 'val': 12, 'test': 12}\n",
        "batch_size = {'train': 128, 'val': 128, 'test': 128}\n",
        "shuffle = {'train': True, 'val': False, 'test': False}\n",
        "\n",
        "# Optimizer\n",
        "optimizer = {'fn': torch.optim.Adam,\n",
        "             'lr': 1e-5,\n",
        "             'betas': [ 0.9, 0.999 ],\n",
        "             'eps': 1e-08,\n",
        "             'weight_decay': 0\n",
        "             }\n",
        "\n",
        "use_lr_scheduler = False\n",
        "\n",
        "lr_scheduler = {'fn': torch.optim.lr_scheduler.CosineAnnealingWarmRestarts,\n",
        "                'T_0': 10,\n",
        "                'T_mult': 2,\n",
        "                'eta_min': 0,\n",
        "                'last_epoch': -1,\n",
        "                'verbose': True}\n",
        "\n",
        "optim = {'optimizer': optimizer, \n",
        "         'use_lr_scheduler': use_lr_scheduler,\n",
        "         'lr_scheduler': lr_scheduler}\n",
        "\n",
        "# Trainer\n",
        "train = {\n",
        "    \"deterministic\": False,\n",
        "    \"random_seed\": 42,\n",
        "    \"val_check_interval\": 1.0,\n",
        "    \"progress_bar_refresh_rate\": 20,\n",
        "    \"fast_dev_run\": False, # True for debug purposes.\n",
        "    \"gpus\": -1 if torch.cuda.is_available() else 0, \n",
        "    \"precision\": 32,\n",
        "    \"max_steps\": 100,\n",
        "    \"max_epochs\": 50,\n",
        "    \"accumulate_grad_batches\": 1,\n",
        "    \"num_sanity_val_steps\": 2,\n",
        "    \"gradient_clip_val\": 10.0\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqjtgwAa3M0c"
      },
      "source": [
        "if train[\"deterministic\"]:\n",
        "    seed_everything(train[\"random_seed\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZuG82jdtS93"
      },
      "source": [
        "W&B login."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNhS-tWzlYYw"
      },
      "source": [
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la7a276GtVQh"
      },
      "source": [
        "Let's setup the trainer and we can run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "cJAu5fPP1MSy"
      },
      "source": [
        "datamodule = SoundscapesDataModule(num_workers=num_workers,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=shuffle)\n",
        "\n",
        "model = SoundscapeDetection(optim=optim)\n",
        "\n",
        "wandb_logger = WandbLogger(\n",
        "    project=\"Soundscapes detection\",\n",
        "    config={\n",
        "        \"batch_size\": batch_size['train'],\n",
        "        \"learning_rate\": optimizer['lr'],\n",
        "        \"optimizer\": optimizer['fn'],\n",
        "        \"betas\": optimizer[\"betas\"],\n",
        "        \"eps\": optimizer[\"eps\"],\n",
        "        \"weight_decay\": optimizer[\"weight_decay\"],\n",
        "        \"T_0\": lr_scheduler[\"T_0\"],\n",
        "        \"T_mult\": lr_scheduler[\"T_mult\"],\n",
        "        \"eta_min\": lr_scheduler[\"eta_min\"],\n",
        "        \"last_epoch\": lr_scheduler[\"last_epoch\"],\n",
        "        \"dataset\": \"Bird CLEF 2021\",\n",
        "        \"summary\": summary(model),\n",
        "        }\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "        logger=wandb_logger,\n",
        "        deterministic=train[\"deterministic\"],\n",
        "        gpus=train[\"gpus\"],\n",
        "        max_epochs=train[\"max_epochs\"],\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CUIYjGDPkXQ"
      },
      "source": [
        "print(summary(model))\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAApxRsI3Xey"
      },
      "source": [
        "Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdeP8zlS3XAV"
      },
      "source": [
        "trainer.fit(model=model, datamodule=datamodule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JPzpg3e3mXi"
      },
      "source": [
        "Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGhgJMxq3mwW"
      },
      "source": [
        "trainer.validate(model=model, datamodule=datamodule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFPpygqStQxa"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_qX9MHefYH8"
      },
      "source": [
        "trainer.test(model=model, datamodule=datamodule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdvNS-mC6aad"
      },
      "source": [
        "Quit W&B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSlm5yeu6cPP"
      },
      "source": [
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}